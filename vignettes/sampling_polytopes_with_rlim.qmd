---
title: "High dimensional polytope sampling with samplelim"
author: "Jacques Bréhélin, Philippe Regnault"
format: html
toc: true
vignette: >
  %\VignetteIndexEntry{High dimensional polytope sampling with samplelim}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

## Describing the polytope to sample

An intersection of hyper-planes and half-spaces defined an $n$-dimensional convex set is known as a polytope $\mathcal{P}$ 
More precisely, $\mathcal{P} = \{ x \in \mathbb{R}^n: Ax = B, Gx \geq H \}$, 
where $A$ is an $m\times n$ matrix, with $m \leq n$, $B \in \mathbb{R}^m$, $G$ is a $k \times n$ matrix, with $k \geq 0$ and $H \in \mathbb{R}^k$. Inequality constraints, represented by the matrix $G$, involved in linear inverse models for metabolic networks make the polytope bounded.

Right below is a minimal toy example defined with the following constraints:

\begin{array}{l}
  1x_1 + 1x_2 + 1x_3 = 1 \\
  0x_1 + 0x_2 + 1x_3 \geq 0.7 \\
  0x_1 + 0x_2 - 1x_3 \geq 0 \\
  0x_1 + 1x_2 + 0x_3 \geq 0.8 \\
  0x_1 - 1x_2 + 0x_3 \geq 0 \\
  1x_1 + 0x_2 + 0x_3 \geq 0.8 \\
  -1x_1 + 0x_2 + 0x_3 \geq 0 \\
\end{array}

Thus, we have $$
\mathbf{A} = \begin{pmatrix}
1 & 1 & 1 
\end{pmatrix}, \quad
\mathbf{B} = \begin{pmatrix}
1
\end{pmatrix}, \quad
\mathbf{G} = \begin{pmatrix}
  0 & 0 & 1 \\
  0 & 0 & -1 \\
  0 & 1 & 0 \\
  0 & -1 & 0 \\
  1 & 0 & 0 \\
  -1 & 0 &0
\end{pmatrix},\quad
\mathbf{H} = \begin{pmatrix}
0.7 \\
0 \\
0.8 \\
0 \\
0.8 \\
0
\end{pmatrix}$$

The main argument `lim` of `rlim()` is a list with (at least) four components named `A`, `B`, `G` and `H`, the matrices and vectors defining the polytope to be sampled. Here those components are set with values of the toy model.

```{r minimalexample}
library("samplelim")
# Define equality and inequality constraints through matrices A, B, G, H
A <- matrix(c(1, 1, 1), nrow = 1, ncol = 3)
B <- 1
G <- -matrix(c(0, 0, 1,
              0, 0, -1,
              0, 1, 0, 
              0, -1, 0,
              1, 0, 0, 
              -1, 0, 0),
            byrow = TRUE,
            nrow = 6, ncol = 3)
H <- -matrix(c(0.7, 0, 0.8, 0, 0.8, 0), nrow = 6)
# Store into a list
lim_exm <- list(A = A, B = B,G = G,H = H)
# Sampling into the polytope defined by these constraints
sample <- rlim(lim_exm, seed = 123)
# Show first points of the sample
head(sample)
```

The sample generated by `rlim()` can be visualized thanks to a 3D scatterplot.

```{r vizminexm, message = FALSE, eval=FALSE}
# Preparing sample for 3D scatterplot
colnames(sample) <- c("X", "Y","Z")
sample <- as.data.frame(sample)
library("plotly")
plot_sample <- plot_ly(sample, x = ~X, y = ~Y, z = ~Z, size = 0.2)
plot_sample <- plot_sample %>% add_markers()
plot_sample <- plot_sample %>% layout(title = "Estimation of the polytope using sample points")
plot_sample
```
![](figures/polytope.png){}

## Sampling the polytope for a model defined in a file

First the model saved in DeclarationFileBOWF-short.txt file is imported and converted into a `lim` object using `df2lim()`.

```{r examplefileimport}
DF <- system.file("extdata", "DeclarationFileBOWF-short.txt", package = "samplelim")
model <- df2lim(DF)
```

All the attributes of the model can be listed as following. 

```{r examplefileattributes}
att <- attributes(model)
att
```

Those attributes can be accessed by using '$attribute' for example variable names .

```{r variable_name}
model$Variables
```

Theoretical ranges for each variable could be determined using `lim.ranges()`. It provides a lower bound, an upper bound, and the range (length of the interval between these bounds).

```{r examplefileranges}
lim.ranges(model)
```

The sampling of the polytope is done using the `rlim()` function.

```{r}
sample <- rlim(model, nsamp=5000, seed = 123)
head(sample)
```

## Adjusting sampling methods and parameters

### Choosing the sample size and sampling method

By default, `rlim()` samples 3000 points using the Mirror Walk algorithm, the sample size can be adjusted and the Billard Walk algorithm can be used instead.

```{r adjusting_ex1, eval = FALSE}
# Set the number of points to sample to 10000 using nsamp
big_sample <- rlim(model, nsamp = 10000, seed = 123)
dim(big_sample)

# Use the Billard Walk algorithm by specifying "BiW" for the type
billard_sample <- rlim(model, type = "BiW", seed = 123)
```

### Parameters of the chain

To achieve a sample closer to a uniform distribution and to reduce auto-correlation between points two integers parameters are usually used: the burn-in (`burn`) and the thinning (`thin`).

Burn-in discards initial values because they are correlated with the starting point. For more information about choosing the burn-in value see [The Raftery and Lewis diagnostic]. 

Thinning is the number of drawn points before adding a new point to the chain. Thinning is used because consecutive points are highly correlated.

```{r adjusting_ex2, eval = FALSE}
burn <- 1000
thin <- 50
burned_and_thinned <- rlim(model, nsamp = 10000, burn=burn, thin=thin, seed = 123)
```


### Adjusting the value of the jump

Both algorithm used for polytope exploration use a parameter called "jump length"  (`jmp`). 

For the Mirror Walk algorithm, direction and length are obtained as the direction and norm of a vector v, where v is s drawn from a centered non correlated Gaussian vector $V = (V1_,...,V_n)$ with Var $V_i = \sigma_i²$. The vector $\sigma^2=(\sigma_1 ²,...,\sigma_n²)$ is called the **jump length**.

For the Billard Walk algorithm, direction is chosen along one axis at each step and the length is drawn from a Gaussian distribution with a single $\sigma$ value for every variable.

Jump (`jmp`) is an important parameter, if its value is too small, exploration of the polytope will not be efficient. Conversely, if the jump is too big the sampling process could take time because the trajectory of the chain may reach borders of the polytope and hence many reflections will need to be computed. 


Finding an optimal value for the jump is difficult, by default `samplelim` use an "adaptative jump" defined as one tenth of each range of the [reduced polytope].

```{r jump_ex1}
# Sampling with default jump (adaptative jump)
default_jump_sample <- rlim(model, nsamp = 1000, seed = 123)

# Get the value of the adaptative jump
# Reduce the polytope
model_reduced <- lim.redpol(model)
# Obtain the ranges of the reduced polytope and divide them by 10
ada_jump <- pol.ranges(G=model_reduced$G,H=model_reduced$H)[,3]/10
ada_jump
```

Custom jump could also be used, for the Billard Walk algorithm a numeric value for $\sigma²$ is needed, for the Mirror Walk the vector $\sigma^2=(\sigma_1 ²,...,\sigma_n²)$, note that $n$, the length of the vector, corresponds to the dimension of the reduced polytope.

```{r jump_ex2}
# Billard Walk
# Set sigma^2 value
sigma2 <- 1
# Sample with chosen jump value
sample_biw <- rlim(model, nsamp = 1000, type = "BiW", jmp=sigma2, seed = 123)

# Mirror Walk
# Get the dimension of the reduced polytope
n=dim(lim.redpol(model)$G)[2]
n
# Create a vector of length n with sigma_i^2 = 4
sigma2_vec= rep(4,n)
# Sample with chosen jump vector
sample_miw <- rlim(model, nsamp = 1000, type = "MiW", jmp=sigma2_vec, seed = 123)
```


## Evaluating the quality of a sample using performance diagnostics

The sampling of a polytope is done using algorithms based on Markov Chain Monte Carlo (MCMC). Those methods are efficient but they require careful assessment to ensure the samples accurately represent the target distribution.

There are multiple tools and criterion known as "diagnostics" to evaluate the convergence of a MCMC, those are applied to the sequences of draws and performed separately for each variable, inducing some insight on the uniformity of the distribution. Here are examples of diagnostics [we use](https://hal.science/hal-04455831/document):


### The Raftery and Lewis diagnostic

The main idea behind the Raftery and Lewis diagnostic is that a correct sample of the objective distribution should give precise estimates of its quantiles. Usually the 0.025 quantile is used.

This diagnostic provides multiple pieces of information, such as the burning values (M), an estimate of the sample size to ensure precise estimation of a prescribed quantile (N), a lower bound (Nmin), and a dependence factor (I).

The dependance factor assesses the extent to which auto-correlation inflates the required sample size; values
larger than 5 indicate a strong auto-correlation.

Raftery and Lewis diagnostic can be perform as following.
```{r RL_diag}
q <- 0.025
RL <- coda::raftery.diag(data = sample, q=q)
RL
```
Note that the value of the flow "FIX->PHY" is greater than 5 indicating a strong auto-correlation.

The maximum burn-in value and estimate sample size can be used to improve the sampling with `rlim()`.
```{r RL_diag2, eval=FALSE}
# Get the maximum value of 'Burn-in' (Burn-in is the first column)
max_burn <- max(RL$resmatrix[,1])
# Get the maximum value of 'Total (N)' (Total (N) is the second column)
max_total <- max(RL$resmatrix[,2])

# Sampling again with those new parameters
better_sample <- rlim(model, nsamp=max_total, burn = max_burn)
```

### The Geweke diagnostic

The Geweke diagnostic is a classical statistical test of comparison of means applied to prescribed proportions of the first and last points generated by an MCMC algorithm. Say 0 < p1 < 1 and 0 < p2 < 1, with p1 + p2 < 1. If the difference
of means is too large, the null hypothesis of convergence is rejected. Usually p1 = 0.1 and p2 = 0.5 are used.

For each variable a value $Z$ is computed, the convergence of the algorithm is rejected if \left| $Z$ \right| exceeds a prescribed quantile of the normal distribution. With p1 = 0.1 and p2 = 0.5, convergence is rejected when \left| $Z$ \right| $\geq$ 1.28 

```{r geweke_diag}
frac1 <- 0.1
frac2 <- 0.5
G <- coda::geweke.diag(sample, frac1 = frac1, frac2 = frac2)
G
```
Note that some values are greater than 1.28.
```{r}
# View which flows with |Z| greater than 1.28
abs(G$z)>=1.28

# Count the number of flows with |Z| greater than 1.28
sum(abs(G$z)>=1.28)
```


### Effective Sample Size

The Effective Sample Size (ESS) reflects the amount of autocorrelation in the MCMC draws. The closer the ESS is to N (where N is the sample size), the better, because it means that the draws are lowly auto-correlated.

```{r ESS_diag}
coda::effectiveSize(sample)
```


## Working with the reduced polytope

The sampling process uses a reduced polytope. The polytope $\mathcal{P} = \{ x \in \mathbb{R}^n: Ax = B, Gx \geq H \}$ is reduced as a polytope $\mathcal{P'} = \{ x \in \mathbb{R}^{n-k}: G'x \geq H' \}$, such that $G' = GZ$, $H' = H-Gx_0$ and $k$ is the rank of the matrix $A$, where the matrix $Z$ is the basis of the right null space of $A$, $x_0$ is a particular solution of $\mathcal{P}$,

> **Note:** The following section is more theoretical and advanced. Studying the reduced polytope can have an interest but it is difficult to interpret for applications in a concrete field.

We can reduce the full polytope and obtain the components describing the reduced polytope using `lim.redpol()`.

```{r projected_polytope_example}
# Get the full polytope
DF <- system.file("extdata", "DeclarationFileBOWF-short.txt", package = "samplelim")
full <- df2lim(DF)
# Project the polytope
reduced <- lim.redpol(full)
# Comparison of the shape of the constraint matrices of the two polytopes
# full
dim(full$G)
# projected
dim(reduced$G)
```

```{r get_project_polytope_comps, eval = FALSE}
# Get k the rank of the matrix A
k <- qr(full$A)$rank
# Get the Z matrix
reduced$Z
# Get the particular solution x0
reduced$x0
# Get the matrix G'
reduced$G
# Get the vector H'
reduced$H
```

The reduced polytope can now be sampled, and this sample can be as a sample of the full polytope using `red2full()` by giving the particular solution $x_0$ and the matrix $Z$.

```{r red2full_example}
# Sampling the reduced polytope
sample_reduced <- rlim(reduced, seed = 123)
head(sample_reduced)
# Turn sampled points of the reduced polytope into sampled points of the full polytope
sample_full <- red2full(sample_reduced, reduced$x0, reduced$Z)
```

A sample of the full polytope can also be turned into a sample of the reduced polytope with `full2red()`.

```{r full2red_example}
sample_reduced2 <- full2red(sample_full,reduced$x0, reduced$Z)
```

