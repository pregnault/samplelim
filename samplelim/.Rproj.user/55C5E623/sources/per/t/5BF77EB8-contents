library("LIM")
library("limSolve")
library("samplelim")
library("GGally")
library(MASS)
library("tidyverse")

sample_lim <- function(A=NULL, B=NULL, E=NULL, F=NULL, G=NULL, H=NULL,
                    sdB=NULL, W=1, iter=3000, outputlength = iter,
                    burninlength = NULL, type="mirror", jmp=NULL,
                    tol=sqrt(.Machine$double.eps), x0=NULL,
                    fulloutput=FALSE, test=TRUE,mode="Mirror")   {
  
  
  
  start=Sys.time()
  norm <- function(x) sqrt(x%*%x)
  
  automatedjump <- function(a,b,g,h,g.scale=5,a.scale=1)   {
    if (is.null(g)) s1 <- rep(NA,k)
    else  {
      q_ranges <- xranges(E=NULL,F=NULL,g,h)
      s1 <- abs(q_ranges[,1]-q_ranges[,2])/g.scale
    }
    s2 <- rep(NA,k)
    if (!is.null(A)) {
      if (estimate_sdB) {
        estVar <- SS0/(lb-lx)*solve(t(a)%*%a) # estimated variance on the parameters, simplified from Brun et al 2001
        estSd  <- sqrt(diag(estVar))
        s2 <- estSd/a.scale
      }
      if (qr(A)$rank==lx&lx==lb)
        s2 <- sdB*.2
    }
    s <- pmin(s1,s2,na.rm=T)
    s[s>tol^-2] <- NA
    if (any (is.na(s)))  {
      if (all(is.na(s)))  {
        warning(" problem is unbounded - all jump lengths are set to 1")
        s[] <- 1
      } else {
        warning(" problem is unbounded - some jump lengths are set arbitrarily")
        s[is.na(s)] <- mean(s,na.rm=T)*100
      }
    }
    return(s)
  }
  
  
  #### 2. the xsample function ####
  
  ## conversions vectors to matrices and checks
  if (is.data.frame(A)) A <- as.matrix(A)
  if (is.data.frame(E)) E <- as.matrix(E)
  if (is.data.frame(G)) G <- as.matrix(G)
  if (is.vector(A)) A <- t(A)
  if (is.vector(E)) E <- t(E)
  if (is.vector(G)) G <- t(G)
  
  if ( !is.null(A) )   {
    lb <- length(B)
    lx <- ncol(A)
    ## system overdetermined?
    M <- rbind(cbind(A,B),cbind(E,F))
    overdetermined <- !qr(M)$rank<=lx
    
    if (overdetermined & is.null(sdB)) {
      warning("The given linear problem is overdetermined. A standard deviation for the data vector B is incorporated in the MCMC as a model parameter.")
      estimate_sdB=TRUE
      A <- A*W
      B <- B*W
    } else {
      estimate_sdB=FALSE
      if (overdetermined)
        warning("The given linear problem is overdetermined. Giving fixed standard deviations for the data vector B can lead to dubious results. Maybe you want to set sdB=NULL and estimate the data error.")
      if (!length(sdB)%in%c(1,lb))
        stop("sdB does not have the correct length")
      A <- A/sdB
      B <- B/sdB           # set sd = 1 in Ax = N(B,sd)
      
    }
  } else {  #is.null A
    estimate_sdB=FALSE
  }
  
  ## find a particular solution x0
  if (is.null(x0))  {
    l <- lsei(A=A,B=B,E=E,F=F,G=G,H=H)
    if (l$residualNorm>1e-6)
      stop("no particular solution found;incompatible constraints")
    else
      x0 <- l$X
  }
  lx <- length(x0)
  
  ## additional checks for equalities, hidden in inequalities... (Karline S.)
  if (test && !is.null(G))   {
    xv <- varranges(E,F,G,H,EqA=G)
    ii <- which (xv[,1]-xv[,2]==0)
    if (length(ii)>0) { # if they exist: add regular equalities !
      E  <- rbind(E,G[ii,])
      F  <- c(F,xv[ii,1])
      
      G  <- G[-ii,]
      H  <- H[-ii]
      if (length(H)==0)
        G <- H <- NULL
    }
    xr <- xranges(E,F,G,H)
    ii <- which (xr[,1]-xr[,2]==0)
    if (length(ii)>0) { # if they exist: add regular equalities !
      dia <- diag(nrow=nrow(xr))
      E  <- rbind(E,dia[ii,])
      F  <- c(F,xr[ii,1])
    }
  }
  
  ## Z is an orthogonal matrix for which E%*%Z=0;
  ## it can serve as basis for the null space of E.
  ## all solutions for the equalities have the form x = x0 + Zq
  ## with q a random vector.
  ## the vector q is varied in a random walk, using a MCMC with
  ## acceptance rate = 1. The inequality constraints Gx>H
  ## can be rewritten as Gx0-H + (GZ)q >0
  
  if (!is.null(E))  {
    Z <- Null(t(E)); Z[abs(Z)<tol] <- 0  #x=x0+Zq ; EZ=0
  } else { Z <- diag(lx) }
  
  if (length(Z)==0)  {
    warning("the problem has a single solution; this solution is returned as function value")
    return(x0)
  }
  k <- ncol(Z)
  
  if (!is.null(G))   {
    g <- G%*%Z
    h <- H-G%*%x0                                            #gq-h>=0
    g[abs(g)<tol] <- 0
    h[abs(h)<tol] <- 0
    
  } else { g <- G; h <- H }
  
  
  if (!is.null(A))   {
    a <- A%*%Z
    b <- B-A%*%x0                          #aq-b~=0
    v <- svd(a,nv=k)$v                     #transformation q <- t(v)q for better convergence
    a <- a%*%v                             #transformation a <- av
    if (!is.null(G)) g <- g%*%v            #transformation g <- gv
    Z <- Z%*%v                             #transformation Z <- Zv
    
    ## if overdetermined, calculate posterior distribution of S in Ax=N(B,S)
    ## Marko Laine 2008, thesis on adaptive mcmc
    ## S = 1/sd^2 of model
    ## prior n0=lb
    ## prior SSR0=n0*s0^2=sum((Ax0-B)^2)=sum(b^2)
    ## if underdetermined: S=1
    ## if overdetermined: S is sampled from a
    ## posterior gamma distribution (Laine 2008) and
    ## standard deviations of data are S^-.5
    if (estimate_sdB)    {
      q0 <- lsei(a,b)$X
      SS0 <- sum((a%*%q0-b)^2)
      S <- lb/SS0
    } else {
      S <- 1
    }
    SSR <- function(q) sum((a%*%q-b)^2)            # sum of squared residuals
    ##        prob <- function(q) prod(dnorm(b,a%*%q,S^-.5))
    prob <- function(q) exp(-.5*S*SSR(q))
    ## test <- function(q2) (prob(q2)/prob(q1))>runif(1) #metropolis criterion
    test <- function(q2) exp(-.5*S*(SSR(q2)-SSR(q1))) > runif(1)
    
  } else {
    prob <- function(q) 1
    test <- function(q2) TRUE
    S <- 1
    overdetermined <- FALSE
  }
  
  outputlength <- min (outputlength,iter)
  ou <- ceiling(iter/outputlength)
  
  q1 <- rep(0,k)
  x <- matrix(nrow=outputlength,ncol=lx,dimnames=list(NULL,colnames(A)))
  x[1,] <- x0
  naccepted <- 1
  p <- vector(length=outputlength) # probability distribution
  p[1] <- prob(q1)
  
  if (fulloutput)   {
    q <- matrix(nrow=outputlength, ncol=k)
    q[1,] <- q1
  }
  
  #if (is.null(jmp)) jmp <- automatedjump(a,b,g,h) # automatedjump(g,h)
  
  
  ## ##################
  ## Building the polytop ##
  ## ##################
  h<-as.numeric(h)
  P <- Hpolytope(A = -g, b = -h)
  stop<-Sys.time()
  #Biw
  if (mode=="Biw"){
    if (is.null(jmp)) {
      random_walk <- list("walk"="BiW")
    }else{
      random_walk <- list("walk"="BiW",L=jmp)
    }
    res_redspace<-as.matrix(volesti::sample_points(P,n=iter,random_walk = random_walk))
  }
  #mirror
  else{
    res_redspace<-as.matrix(samplelim::sample_points(P,n=iter,random_walk = list("walk"="mirror","jump"=jmp)))
  }
  #
  
  res<-x0+Z%*%res_redspace
  x<-t(res)

  
  xnames <- colnames(A)
  if (is.null(xnames)) xnames <- colnames(E)
  if (is.null(xnames)) xnames <- colnames(G)
  colnames (x) <- xnames
  
  
  return(list("res"=x,"build_time"=stop-start))
}



filename="modeles/DeclarationFileBOWF.txt"
web.lim<- df_to_lim(filename)

bench<-data.frame(modele=character(),nUnknowns=integer(),algo=character(),iter=integer(),time=double())
rowNumber=1

E=web.lim$A
F=web.lim$B
G=web.lim$G
H=web.lim$H
niter=20000
ranges_pol<-ranges_red_pol(E=E,F=F,G=G,H=H)
jump_rlim<-0.01*ranges_pol[,3]
for (i in 1:10){
  for (alg in c("Biw","Mirror")){
    bench[rowNumber,1]="Urban"
    bench[rowNumber,2]=69
    bench[rowNumber,3]=alg
    bench[rowNumber,4]=i
    print(paste(alg,i))
    if (alg=="Mirror"){

      t<-system.time(raw_data<-sample_lim(E=E,F=F,G=G,H=H, iter=niter,jmp=jump_rlim,mode=alg))[[3]]
    }else{
      t<-system.time(raw_data<-sample_lim(E=E,F=F,G=G,H=H, iter=niter,mode=alg))[[3]]
    }
    write.csv(raw_data,paste(paste("echantillons/urban/_urban",alg,niter,i,sep = "_"),".csv"))
    bench[rowNumber,5]<-t
    rowNumber<-rowNumber+1 
  }
  write.csv(bench,"bench_urban.csv")
}


write.csv(raw_data,"bench_urban.csv")









time_bm<-tibble(n=0,t_sampleLIM=system.time(exp=NULL)[[3]],t_Xsample=system.time(exp=NULL)[[3]])
n<-c(50,100,500,1000,5000,10000,50000)
for (i in 1:length(n)){
  time_bm[i+1,1]<-n[i]
  time_bm[i+1,2]<-system.time(expr=sample_lim(E=web.lim$A,F=web.lim$B,G=web.lim$G,H=web.lim$H, iter=n[i],jmp=jump))[[3]]
  time_bm[i+1,3]<-system.time(expr=xsample(E=web.lim$A,F=web.lim$B,G=web.lim$G,H=web.lim$H, iter=n[i],jmp=jump))[[3]]
}
#res_xsample<-sample_lim(E=web.lim$A,F=web.lim$B,G=web.lim$G,H=web.lim$H, iter=5,jmp=0.006)

res_sampleLIM<-sample_lim(E=pol$A,F=pol$b,G=-pol$G,H=-pol$h, iter=20000,jmp=jump)
colnames(res_sampleLIM)<-web.lim$Unknowns
res_sampleLIM<-as_tibble(res_sampleLIM)
res_xsample<-xsample(E=web.lim$A,F=web.lim$B,G=web.lim$G,H=web.lim$H, iter=n[i],jmp=jump)
res_xsample<-res_xsample$X
colnames(res_xsample)<-web.lim$Unknowns
res_xsample<-as_tibble(res_xsample)

res_biw<-sample_lim(E=pol$A,F=pol$b,G=-pol$G,H=-pol$h, iter=20000,jmp=jump)
colnames(res_biw)<-web.lim$Unknowns
res_biw<-as_tibble(res_biw)

ggpairs(res_sampleLIM,columns=1:5, lower=list(continuous=wrap("points",alpha=0.3,size=0.1),combo=wrap("dot",alpha=0.4,size=0.2)),title =paste(filename,"SampleLIM"))
ggpairs(res_xsample,columns=1:5, lower=list(continuous=wrap("points",alpha=0.3,size=0.1),combo=wrap("dot",alpha=0.4,size=0.2)),title =paste(filename,"xsample"))
ggpairs(res_biw,columns=1:5, lower=list(continuous=wrap("points",alpha=0.3,size=0.1),combo=wrap("dot",alpha=0.4,size=0.2)),title =paste(filename,"Biw"))


matplot(x=time_bm$n,y=time_bm[,2:3], xlab="n",ylab="time (s)",type = "l",pch=1,col = c("blue","red"))
legend("topleft", legend = c("SampleLIM","xsample"), col=c("blue","red"), pch=16)
