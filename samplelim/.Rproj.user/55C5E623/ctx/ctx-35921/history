}
for (jump_type in c("fixe","adaptatif")){
if (jump_type=="fixe"){
for (jmp in jump_fixe){
print(paste(i,jump_type,jmp))
name<-paste(paste("echantillons/jump_rlim/BOWF_rlim_1000_jump_",jump_type,jmp,i,sep = "_"),".csv",sep="")
t<-system.time(raw_data<-rlim(lim, iter=niter,jmp=jmp))[[3]]
write.csv(raw_data,name)
bench[rowNumber,1]=modele
bench[rowNumber,2]=144
bench[rowNumber,3]="rlim"
bench[rowNumber,4]=jump_type
bench[rowNumber,5]=jmp
bench[rowNumber,6]=i
bench[rowNumber,7]=t
bench[rowNumber,8]=name
rowNumber<-rowNumber+1
}}
if (jump_type=="adaptatif"){
for (jmp in jump_adaptatif){
print(paste(i,jump_type,jmp))
name<-paste(paste("echantillons/jump_rlim/BOWF_rlim_1000_jump_",jump_type,jmp,i,sep = "_"),".csv",sep="")
t<-system.time(raw_data<-rlim(lim, iter=niter,jmp=jmp*ranges))[[3]]
bench[rowNumber,1]=modele
bench[rowNumber,2]=144
bench[rowNumber,3]="rlim"
bench[rowNumber,4]=jump_type
bench[rowNumber,5]=jmp
bench[rowNumber,6]=i
bench[rowNumber,7]=t
bench[rowNumber,8]=name
rowNumber<-rowNumber+1
}}
}
}
View(bench)
save(bench,file="echantillons/jump_corrected/bench.Rdata")
View(bench)
for (i in 1:10){
#for (jmp in jump_biw){
print(paste(i,"volesti",jmp))
name<-paste(paste("echantillons/jump_corrected/BOWF_biw_1000_jump_auto",i,sep = "_"),".csv",sep="")
t<-system.time(raw_data<-volesti_rlim(lim, iter=niter))[[3]]
write.csv(raw_data,name)
bench[rowNumber,1]=modele
bench[rowNumber,2]=144
bench[rowNumber,3]="sample_points"
bench[rowNumber,4]="auto"
bench[rowNumber,5]=NA
bench[rowNumber,6]=i
bench[rowNumber,7]=t
bench[rowNumber,8]=name
rowNumber<-rowNumber+1
#}
# for (jump_type in c("fixe","adaptatif")){
#   if (jump_type=="fixe"){
#     for (jmp in jump_fixe){
#       print(paste(i,jump_type,jmp))
#       name<-paste(paste("echantillons/jump_rlim/BOWF_rlim_1000_jump_",jump_type,jmp,i,sep = "_"),".csv",sep="")
#       t<-system.time(raw_data<-rlim(lim, iter=niter,jmp=jmp))[[3]]
#       write.csv(raw_data,name)
#       bench[rowNumber,1]=modele
#       bench[rowNumber,2]=144
#       bench[rowNumber,3]="rlim"
#       bench[rowNumber,4]=jump_type
#       bench[rowNumber,5]=jmp
#       bench[rowNumber,6]=i
#       bench[rowNumber,7]=t
#       bench[rowNumber,8]=name
#       rowNumber<-rowNumber+1
#
#     }}
#   if (jump_type=="adaptatif"){
#     for (jmp in jump_adaptatif){
#
#       print(paste(i,jump_type,jmp))
#       name<-paste(paste("echantillons/jump_rlim/BOWF_rlim_1000_jump_",jump_type,jmp,i,sep = "_"),".csv",sep="")
#       t<-system.time(raw_data<-rlim(lim, iter=niter,jmp=jmp*ranges))[[3]]
#       bench[rowNumber,1]=modele
#       bench[rowNumber,2]=144
#       bench[rowNumber,3]="rlim"
#       bench[rowNumber,4]=jump_type
#       bench[rowNumber,5]=jmp
#       bench[rowNumber,6]=i
#       bench[rowNumber,7]=t
#       bench[rowNumber,8]=name
#       rowNumber<-rowNumber+1
#
#     }}
#
#
#
#
#   }
}
View(bench)
save(bench,file="echantillons/jump_corrected/bench.Rdata")
current_row<-list(modele=character(),nUnknowns=integer(),sampleSize=integer(),algo=character(),jmp_type=character(),jmp=double(),sampleIndex=integer(),fluxIndex=double(),flux_min=double(),flux_max=double(),flux_mean=double(),flux_median=double(),flux_Q1=double(),flux_Q3=double(),time=double(),Geweke=double(),HD=double(),ESS=double(),sample=list())
jump_dataset_corrected=list()
m="BOWF"
current_row["modele"]=m
current_row["nUnknowns"]=144
current_row["sampleSize"]=niter
for (n in 1:nrow(bench)){
print(n)
row_bench<-bench[n,]
current_row["modele"]=row_bench[1]
current_row["nUnknowns"]=144
current_row["sampleSize"]=niter
current_row["time"]=row_bench[7]
alg=row_bench[3]
current_row["algo"]=alg
i=row_bench[6]
current_row["sampleIndex"]=i
jmp_type=row_bench[4]
jmp=row_bench[5]
current_row["jmp_type"]=jmp_type
current_row["jmp"]=jmp
sample<-read.csv(row_bench[8],header = TRUE)[,2:145]
for (j in 1:144){
current_row["fluxIndex"]=j
flux_sample<-c(sample[,j])
current_row["sample"]<-list(flux_sample)
sample_quantiles<-quantile(flux_sample,names=FALSE)
current_row["flux_min"]<-sample_quantiles[1]
current_row["flux_Q1"]<-sample_quantiles[2]
current_row["flux_median"]<-sample_quantiles[3]
current_row["flux_Q3"]<-sample_quantiles[4]
current_row["flux_max"]<-sample_quantiles[5]
current_row["flux_mean"]<-mean(flux_sample)
#Raftery Lewis
data<-mcmc(data= flux_sample, start = 1, end = 1000, thin = 1)
#raftery_lewis<-raftery.diag(data, q=0.025, r=0.005, s=0.95, converge.eps=0.001)
#res_rl<-raftery_lewis[["resmatrix"]]
# current_row["RL_M"]<-res_rl[[1,1]]
# current_row["RL_N"]<-res_rl[[1,2]]
# current_row["RL_Nmin"]<-res_rl[[1,3]]
# current_row["RL_I"]<-res_rl[[1,4]]
# current_row["RL_k"]<-res_rl[[1,5]]
#Geweke
current_row["Geweke"]<-geweke.diag(data, frac1=0.1, frac2=0.5)$z
#Hellinger Distance
r1<-as.integer(niter/3)
r2<-as.integer(2*niter/3)
p1<-as.vector(flux_sample[1:r1])
p1_dens<-densityfun(p1)
p3<-as.vector(flux_sample[r2:niter])
p3_dens<-densityfun(p3)
fun <-function(x) (sqrt(p1_dens(x))-sqrt(p3_dens(x)))**2
current_row["HD"]<-sqrt(0.5*integral(fun=fun,-Inf,Inf) )
#ESS
current_row["ESS"]<-effectiveSize(data)
# Add to big dataset
jump_dataset_corrected<-rbind(jump_dataset_corrected,current_row)
}
}
row_bench[8]
row_bench[[8]]
for (n in 1:nrow(bench)){
print(n)
row_bench<-bench[n,]
current_row["modele"]=row_bench[1]
current_row["nUnknowns"]=144
current_row["sampleSize"]=niter
current_row["time"]=row_bench[7]
alg=row_bench[3]
current_row["algo"]=alg
i=row_bench[6]
current_row["sampleIndex"]=i
jmp_type=row_bench[4]
jmp=row_bench[5]
current_row["jmp_type"]=jmp_type
current_row["jmp"]=jmp
sample<-read.csv(row_bench[[8]],header = TRUE)[,2:145]
for (j in 1:144){
current_row["fluxIndex"]=j
flux_sample<-c(sample[,j])
current_row["sample"]<-list(flux_sample)
sample_quantiles<-quantile(flux_sample,names=FALSE)
current_row["flux_min"]<-sample_quantiles[1]
current_row["flux_Q1"]<-sample_quantiles[2]
current_row["flux_median"]<-sample_quantiles[3]
current_row["flux_Q3"]<-sample_quantiles[4]
current_row["flux_max"]<-sample_quantiles[5]
current_row["flux_mean"]<-mean(flux_sample)
#Raftery Lewis
data<-mcmc(data= flux_sample, start = 1, end = 1000, thin = 1)
#raftery_lewis<-raftery.diag(data, q=0.025, r=0.005, s=0.95, converge.eps=0.001)
#res_rl<-raftery_lewis[["resmatrix"]]
# current_row["RL_M"]<-res_rl[[1,1]]
# current_row["RL_N"]<-res_rl[[1,2]]
# current_row["RL_Nmin"]<-res_rl[[1,3]]
# current_row["RL_I"]<-res_rl[[1,4]]
# current_row["RL_k"]<-res_rl[[1,5]]
#Geweke
current_row["Geweke"]<-geweke.diag(data, frac1=0.1, frac2=0.5)$z
#Hellinger Distance
r1<-as.integer(niter/3)
r2<-as.integer(2*niter/3)
p1<-as.vector(flux_sample[1:r1])
p1_dens<-densityfun(p1)
p3<-as.vector(flux_sample[r2:niter])
p3_dens<-densityfun(p3)
fun <-function(x) (sqrt(p1_dens(x))-sqrt(p3_dens(x)))**2
current_row["HD"]<-sqrt(0.5*integral(fun=fun,-Inf,Inf) )
#ESS
current_row["ESS"]<-effectiveSize(data)
# Add to big dataset
jump_dataset_corrected<-rbind(jump_dataset_corrected,current_row)
}
}
View(bench)
bench2<-bench[bench$jump_type != "adaptatif"]
bench2<-bench[bench$jump_type != "adaptatif",]
View(bench2)
bench<-data.frame(modele=character(),nUnknowns=integer(),algo=character(),jump_type=character(),jump=double(),sample_index=integer(),time=double(),name=character())
niter=1000
rowNumber<-1
for (i in 1:10){
# #for (jmp in jump_biw){
#   print(paste(i,"volesti",jmp))
#   name<-paste(paste("echantillons/jump_corrected/BOWF_biw_1000_jump_auto",i,sep = "_"),".csv",sep="")
# t<-system.time(raw_data<-volesti_rlim(lim, iter=niter))[[3]]
# write.csv(raw_data,name)
# bench[rowNumber,1]=modele
# bench[rowNumber,2]=144
# bench[rowNumber,3]="sample_points"
# bench[rowNumber,4]="auto"
# bench[rowNumber,5]=NA
# bench[rowNumber,6]=i
# bench[rowNumber,7]=t
# bench[rowNumber,8]=name
#
# rowNumber<-rowNumber+1
# #}
for (jump_type in c("adaptatif")){
if (jump_type=="fixe"){
for (jmp in jump_fixe){
print(paste(i,jump_type,jmp))
name<-paste(paste("echantillons/jump_corrected/BOWF_rlim_1000_jump_",jump_type,jmp,i,sep = "_"),".csv",sep="")
t<-system.time(raw_data<-rlim(lim, iter=niter,jmp=jmp))[[3]]
write.csv(raw_data,name)
bench[rowNumber,1]=modele
bench[rowNumber,2]=144
bench[rowNumber,3]="rlim"
bench[rowNumber,4]=jump_type
bench[rowNumber,5]=jmp
bench[rowNumber,6]=i
bench[rowNumber,7]=t
bench[rowNumber,8]=name
rowNumber<-rowNumber+1
}}
if (jump_type=="adaptatif"){
for (jmp in jump_adaptatif){
print(paste(i,jump_type,jmp))
name<-paste(paste("echantillons/jump_corrected/BOWF_rlim_1000_jump_",jump_type,jmp,i,sep = "_"),".csv",sep="")
t<-system.time(raw_data<-rlim(lim, iter=niter,jmp=jmp*ranges))[[3]]
write.csv(raw_data,name)
bench[rowNumber,1]=modele
bench[rowNumber,2]=144
bench[rowNumber,3]="rlim"
bench[rowNumber,4]=jump_type
bench[rowNumber,5]=jmp
bench[rowNumber,6]=i
bench[rowNumber,7]=t
bench[rowNumber,8]=name
rowNumber<-rowNumber+1
}}
}
}
bench<-rbind(bench,bench2)
save(bench,file="echantillons/jump_corrected/bench.Rdata")
current_row<-list(modele=character(),nUnknowns=integer(),sampleSize=integer(),algo=character(),jmp_type=character(),jmp=double(),sampleIndex=integer(),fluxIndex=double(),flux_min=double(),flux_max=double(),flux_mean=double(),flux_median=double(),flux_Q1=double(),flux_Q3=double(),time=double(),Geweke=double(),HD=double(),ESS=double(),sample=list())
jump_dataset_corrected=list()
m="BOWF"
current_row["modele"]=m
current_row["nUnknowns"]=144
current_row["sampleSize"]=niter
for (n in 1:nrow(bench)){
print(n)
row_bench<-bench[n,]
current_row["modele"]=row_bench[1]
current_row["nUnknowns"]=144
current_row["sampleSize"]=niter
current_row["time"]=row_bench[7]
alg=row_bench[3]
current_row["algo"]=alg
i=row_bench[6]
current_row["sampleIndex"]=i
jmp_type=row_bench[4]
jmp=row_bench[5]
current_row["jmp_type"]=jmp_type
current_row["jmp"]=jmp
sample<-read.csv(row_bench[[8]],header = TRUE)[,2:145]
for (j in 1:144){
current_row["fluxIndex"]=j
flux_sample<-c(sample[,j])
current_row["sample"]<-list(flux_sample)
sample_quantiles<-quantile(flux_sample,names=FALSE)
current_row["flux_min"]<-sample_quantiles[1]
current_row["flux_Q1"]<-sample_quantiles[2]
current_row["flux_median"]<-sample_quantiles[3]
current_row["flux_Q3"]<-sample_quantiles[4]
current_row["flux_max"]<-sample_quantiles[5]
current_row["flux_mean"]<-mean(flux_sample)
#Raftery Lewis
data<-mcmc(data= flux_sample, start = 1, end = 1000, thin = 1)
#raftery_lewis<-raftery.diag(data, q=0.025, r=0.005, s=0.95, converge.eps=0.001)
#res_rl<-raftery_lewis[["resmatrix"]]
# current_row["RL_M"]<-res_rl[[1,1]]
# current_row["RL_N"]<-res_rl[[1,2]]
# current_row["RL_Nmin"]<-res_rl[[1,3]]
# current_row["RL_I"]<-res_rl[[1,4]]
# current_row["RL_k"]<-res_rl[[1,5]]
#Geweke
current_row["Geweke"]<-geweke.diag(data, frac1=0.1, frac2=0.5)$z
#Hellinger Distance
r1<-as.integer(niter/3)
r2<-as.integer(2*niter/3)
p1<-as.vector(flux_sample[1:r1])
p1_dens<-densityfun(p1)
p3<-as.vector(flux_sample[r2:niter])
p3_dens<-densityfun(p3)
fun <-function(x) (sqrt(p1_dens(x))-sqrt(p3_dens(x)))**2
current_row["HD"]<-sqrt(0.5*integral(fun=fun,-Inf,Inf) )
#ESS
current_row["ESS"]<-effectiveSize(data)
# Add to big dataset
jump_dataset_corrected<-rbind(jump_dataset_corrected,current_row)
}
}
#rangelist
theorical_min<-c()
theorical_max<-c()
rangeCoverage<-c()
for (i in 1:nrow(jump_dataset_corrected)){
minimum<-real_ranges[jump_dataset_corrected[[i,8]],1]
theorical_min<-append(theorical_min,minimum)
maximum<-real_ranges[jump_dataset_corrected[[i,8]],2]
theorical_max<-append(theorical_max,maximum)
rangeC<-(jump_dataset_corrected[[i,10]]-jump_dataset_corrected[[i,9]])/(maximum-minimum)
if (jump_dataset_corrected[[i,10]]>maximum | jump_dataset_corrected[[i,9]]<minimum){
rangeC=NA
}
if (maximum==minimum){
rangeC<-NA
}
rangeCoverage<-append(rangeCoverage,rangeC)
}
jump_dataset_corrected<-cbind(jump_dataset_corrected,theorical_min,theorical_max,rangeCoverage)
save(jump_dataset_corrected,file="echantillons/jump_corrected/jump_dataset_corrected.Rdata")
jump_dataset_corrected<-as_tibble(jump_dataset_corrected)
jump_bench_corrected<-jump_dataset_corrected %>% mutate(fluxIndex=as.numeric(fluxIndex))%>%
mutate(time=as.numeric(time),Geweke=as.numeric(Geweke),ESS=as.numeric(ESS),rangeCoverage=as.numeric(rangeCoverage)) %>%
mutate(Geweke_test=as.numeric(abs(Geweke)>1.28)) %>%
group_by(algo,jmp_type,jmp) %>%
mutate(time=mean(time),G=sum(Geweke_test,na.rm = TRUE)/144,ESSmean=round(mean(ESS,na.rm=TRUE)),meanRC=round(mean(rangeCoverage,na.rm=TRUE),digits=5)) %>%
subset(select=c("algo","jmp_type","jmp","time","G","ESSmean","meanRC")) %>%
distinct()
View(jump_bench_corrected)
jump_bench_corrected<-jump_bench_corrected%>%mutate(group=paste(algo,jmp_type,sep=" "))
jump_bench_synthese<-jump_bench_corrected
save(jump_bench_synthese,file="echantillon/jump_corrected/jump_bench_synthese.Rdata")
save(jump_bench_synthese,file="echantillons/jump_corrected/jump_bench_synthese.Rdata")
ggplot(jump_bench_synthese,group=group)+geom_point(aes(x=time,y=ESSmean,col=group))
ggplot(jump_bench_synthese,group=group)+geom_point(aes(x=time,y=meanRC,col=group))
ggplot(jump_bench_synthese,group=group)+geom_point(aes(x=time,y=ESSmean,col=group))
setwd("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB")
load("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB/echantillons/jump_corrected/jump_bench_synthese.Rdata")
View(jump_bench_synthese)
library(tidyverse)
ggplot(filter(jump_bench_synthese,group=="rlim fixe"))+geom_point(aes(x=jmp,y=time))
ggplot(filter(jump_bench_synthese,group=="rlim fixe"))+geom_point(aes(x=as.double(jmp),y=time))
ggplot(filter(jump_bench_synthese,group=="rlim adaptatif"))+geom_point(aes(x=as.double(jmp),y=time))
lm(time~as.double(jmp),data=filter(jump_bench_synthese,group=="rlim adaptatif"))
lm(time~as.double(jmp),data=filter(jump_bench_synthese,group=="rlim fixe"))
ggplot(jump_bench_synthese,group=group)+geom_point(aes(x=time,y=ESSmean,col=group))
ggplot(jump_bench_synthese,group=group)+geom_point(aes(x=time,y=G,col=group))
jump_bench_synthese[47,5]<-jump_bench_synthese[47,5]/2
jump_bench_synthese[49,5]<-jump_bench_synthese[49,5]/2
ggplot(jump_bench_synthese,group=group)+geom_point(aes(x=time,y=G,col=group))
load("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB/bench_jump.Rdata")
View(bench_jump)
ggplot(bench_jump,group=group)+geom_point(aes(x=time,y=G,col=group))
ggplot(bench_jump,group=group)+geom_point(aes(x=time,y=ESSmean,col=group))
setwd("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB")
load("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB/echantillons/bowf_bench_synthese.Rdata")
View(bowf_bench_corrected)
library(xtable)
print(xtable(bowf_bench_corrected))
load("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB/bench_jump_bowf.Rdata")
View(bench_jump)
library(samplelim)
lim<-df_to_lim("modeles/DeclarationFileBOWF.txt")
red_pol<-full_dim_poly(A=lim$A,B=lim$B,G=lim$G,H=lim$H)
View(red_pol)
P=Hpolytope(A=-red_pol$G,b=-red_pol$H)
inner_ball(P)
ranges_red_pol<-lim_autojump(lim,scale=1)
mean(ranges_red_pol)
load("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB/echantillons/bowf_dataset.Rdata")
View(bowf_dataset_corrected)
test<-filter((bowf_dataset_corrected,jmp==100))
test<-filter(bowf_dataset_corrected,jmp==100)
library(tidyverse)
test<-filter(bowf_dataset_corrected,jmp==100)
bowf_dataset_corrected<-as_tibble(bowf_dataset_corrected)
test<-filter(bowf_dataset_corrected,jmp==100)
View(test)
library(coda)
?raftery.diag
lim_urban<-df_to_lim("urban/gueret_UNB_VIE+_2015_COMPOST.txt")
View(lim_urban)
View(lim_urban$A)
View(lim_urban$G)
G<-lim_urban$G
g=c()
for (i in 1:302){
g=c(g,sum(G[i,]))
}
?which
which(g!=1 | g!= -1)
which(g!=1 & g!= -1)
?count
g=c()
for (i in 1:302){
f=0
for (j in 1:69){
if(G[i,j]!=0){
f=f+1
}
}
g=c(g,f)
}
which(g!=1)
View(bowf_bench_corrected)
load("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB/BOWF_jump_resume.Rdata")
View(BOWF_jump_resume)
ranges<-lim_ranges(lim)
View(ranges)
UseMethod("cov")
UseMethod(cov)
cov
?cov
library(samplelim)
setwd("/media/theo/TOSHIBA EXT/PostDoc_Nestore/packages/samplelim/samplelim/R")
setwd("/media/theo/TOSHIBA EXT/PostDoc_Nestore/WorkInProgress/XP_JMB")
metabolic_net_2_matrix <- function(path) {
modelmat = R.matlab::readMat(path)
modelmat = modelmat[1]
modelmat = modelmat[[1]]
el = 11
if(dim(modelmat[[11]])[1] > dim(modelmat[[11]])[2]) {
el = el -1
}
A = modelmat[[el]]
#Aeq=matrix(Aeq,ncol = ncol(Aeq), nrow = nrow(Aeq))
lb = as.vector(modelmat[[el+1]])
ub = as.vector(modelmat[[el+2]])
b = as.vector(modelmat[[el+3]])
obj = as.vector(modelmat[[el+4]])
d = dim(A)[2]
G = rbind(diag(d), -diag(d))
h = c(ub, -lb)
HP = list(G = -G, H = -h, A = A, B= b)
return(HP)
}
path = 'modeles/e_coli_core.mat'
lim_ecoli<-metabolic_net_2_matrix(path)
ecoli_ranges<-lim_ranges(lim_ecoli)
View(ecoli_ranges)
sample<-rlim(lim_ecoli)
View(sample)
View(lim_ecoli)
ranges_ecoli<-lim_ranges(lim_ecoli)
View(ranges_ecoli)
ranges_pol<-poly_ranges(G=lim_ecoli$G,H=lim_ecoli$H)
View(ranges_pol)
A<-read.csv(file="modeles/ecoli_A.csv",header=FALSE)
b<-read.csv(file="modeles/ecoli_b.csv",header=FALSE)
P=Hpolytope(A=A,b=b)
A<-matrix(A)
View(A)
A<-read.csv(file="modeles/ecoli_A.csv",header=FALSE)
A<-as.matrix(A)
b<-as.numeric(b)
View(b)
b<-as.numeric(b["V1"])
b<-as.numeric(b[["V1"]])
P=Hpolytope(A=A,b=b)
inner_ball(P)
ranges_G<-poly_ranges(G=lim_ecoli$G,H=lim_ecoli$H)
View(ranges_G)
View(ranges_ecoli)
View(ranges_ecoli)
lim_ecoli$G[c(50,51),]
add_eq<-matrix(data=0,nrow = 2,ncol=95)
ii=c(50,51)
for (iseq in ii) { # if they exist: add regular equalities !
add_eq<-rep(0,95)
add_eq[iseq]<-1
A  <- rbind(A,add_eq)
B  <- c(B,xv[iseq,1])
}
library(samplelim)
red_pol_ecoli<-lim_full_dim_poly(lim_ecoli)
View(red_pol_ecoli)
P<-Hpolytope(A=-red_pol_ecoli$G,b=-red_pol_ecoli$H)
inner_ball(P)
sample<-rlim(lim_ecoli)
View(sample)
View(ranges_ecoli)
